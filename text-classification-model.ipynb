{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport transformers\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import DistilBertModel, DistilBertTokenizer","metadata":{"execution":{"iopub.status.busy":"2022-11-24T03:28:57.321500Z","iopub.execute_input":"2022-11-24T03:28:57.321861Z","iopub.status.idle":"2022-11-24T03:28:58.363866Z","shell.execute_reply.started":"2022-11-24T03:28:57.321831Z","shell.execute_reply":"2022-11-24T03:28:58.361724Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch import cuda\ndevice = \"cuda\" if cuda.is_available() else \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2022-11-24T03:29:36.493553Z","iopub.execute_input":"2022-11-24T03:29:36.493954Z","iopub.status.idle":"2022-11-24T03:29:36.627162Z","shell.execute_reply.started":"2022-11-24T03:29:36.493920Z","shell.execute_reply":"2022-11-24T03:29:36.625948Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"MAX_LEN = 512\nTRAIN_BATCH_SIZE = 4\nVALID_BATCH_SIZE = 2\nEPOCHS = 1\nLEARNING_RATE = 1e-05","metadata":{"execution":{"iopub.status.busy":"2022-11-24T03:32:28.166227Z","iopub.execute_input":"2022-11-24T03:32:28.166651Z","iopub.status.idle":"2022-11-24T03:32:28.171695Z","shell.execute_reply.started":"2022-11-24T03:32:28.166620Z","shell.execute_reply":"2022-11-24T03:32:28.170469Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv', delimiter='\\t', header=None)","metadata":{"execution":{"iopub.status.busy":"2022-11-24T03:30:49.749927Z","iopub.execute_input":"2022-11-24T03:30:49.750358Z","iopub.status.idle":"2022-11-24T03:30:51.202413Z","shell.execute_reply.started":"2022-11-24T03:30:49.750323Z","shell.execute_reply":"2022-11-24T03:30:51.201461Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-24T03:40:12.590181Z","iopub.execute_input":"2022-11-24T03:40:12.590583Z","iopub.status.idle":"2022-11-24T03:40:12.602864Z","shell.execute_reply.started":"2022-11-24T03:40:12.590553Z","shell.execute_reply":"2022-11-24T03:40:12.601540Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"                                                   0  1\n0  a stirring , funny and finally transporting re...  1\n1  apparently reassembled from the cutting room f...  0\n2  they presume their audience wo n't sit still f...  0\n3  this is a visually stunning rumination on love...  1\n4  jonathan parker 's bartleby should have been t...  1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a stirring , funny and finally transporting re...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>apparently reassembled from the cutting room f...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>they presume their audience wo n't sit still f...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>this is a visually stunning rumination on love...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>jonathan parker 's bartleby should have been t...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoTokenizer\nmodel_ckpt = \"distilbert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(model_ckpt)","metadata":{"execution":{"iopub.status.busy":"2022-11-24T03:33:01.299099Z","iopub.execute_input":"2022-11-24T03:33:01.299814Z","iopub.status.idle":"2022-11-24T03:33:02.787378Z","shell.execute_reply.started":"2022-11-24T03:33:01.299780Z","shell.execute_reply":"2022-11-24T03:33:02.786358Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"class Triage(Dataset):\n    def __init__(self, dataframe, tokenizer, max_len):\n        self.len = len(dataframe)\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        \n    def __getitem__(self, index):\n        text = self.data.iloc[index, 0]\n        inputs = self.tokenizer.encode_plus(\n            text,\n            None,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            pad_to_max_length=True,\n            return_token_type_ids=True,\n            truncation=True\n        )\n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']\n\n        return {\n            'ids': torch.tensor(ids, dtype=torch.long),\n            'mask': torch.tensor(mask, dtype=torch.long),\n            'targets': torch.tensor(self.data.iloc[index, 1], dtype=torch.long)\n        } \n    \n    def __len__(self):\n        return self.len","metadata":{"execution":{"iopub.status.busy":"2022-11-24T03:42:26.067164Z","iopub.execute_input":"2022-11-24T03:42:26.067603Z","iopub.status.idle":"2022-11-24T03:42:26.076394Z","shell.execute_reply.started":"2022-11-24T03:42:26.067569Z","shell.execute_reply":"2022-11-24T03:42:26.075060Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"train_size = 0.8\ntrain_dataset=df.sample(frac=train_size,random_state=200)\ntest_dataset=df.drop(train_dataset.index).reset_index(drop=True)\ntrain_dataset = train_dataset.reset_index(drop=True)\n\n\nprint(\"FULL Dataset: {}\".format(df.shape))\nprint(\"TRAIN Dataset: {}\".format(train_dataset.shape))\nprint(\"TEST Dataset: {}\".format(test_dataset.shape))\n\ntraining_set = Triage(train_dataset, tokenizer, MAX_LEN)\ntesting_set = Triage(test_dataset, tokenizer, MAX_LEN)","metadata":{"execution":{"iopub.status.busy":"2022-11-24T03:42:27.042477Z","iopub.execute_input":"2022-11-24T03:42:27.042842Z","iopub.status.idle":"2022-11-24T03:42:27.057855Z","shell.execute_reply.started":"2022-11-24T03:42:27.042813Z","shell.execute_reply":"2022-11-24T03:42:27.056593Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"FULL Dataset: (6920, 2)\nTRAIN Dataset: (5536, 2)\nTEST Dataset: (1384, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"train_params = {'batch_size': TRAIN_BATCH_SIZE,\n                'shuffle': True,\n                'num_workers': 0\n                }\n\ntest_params = {'batch_size': VALID_BATCH_SIZE,\n                'shuffle': True,\n                'num_workers': 0\n                }\n\ntraining_loader = DataLoader(training_set, **train_params)\ntesting_loader = DataLoader(testing_set, **test_params)","metadata":{"execution":{"iopub.status.busy":"2022-11-24T03:42:28.489060Z","iopub.execute_input":"2022-11-24T03:42:28.489749Z","iopub.status.idle":"2022-11-24T03:42:28.495508Z","shell.execute_reply.started":"2022-11-24T03:42:28.489702Z","shell.execute_reply":"2022-11-24T03:42:28.494276Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"class DistillBERTClass(torch.nn.Module):\n    def __init__(self):\n        super(DistillBERTClass, self).__init__()\n        self.l1 = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n        self.pre_classifier = torch.nn.Linear(768, 768)\n        self.dropout = torch.nn.Dropout(0.3)\n        self.classifier = torch.nn.Linear(768, 4)\n\n    def forward(self, input_ids, attention_mask):\n        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n        hidden_state = output_1[0]\n        pooler = hidden_state[:, 0]\n        pooler = self.pre_classifier(pooler)\n        pooler = torch.nn.ReLU()(pooler)\n        pooler = self.dropout(pooler)\n        output = self.classifier(pooler)\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-11-24T03:42:29.900093Z","iopub.execute_input":"2022-11-24T03:42:29.900703Z","iopub.status.idle":"2022-11-24T03:42:29.908441Z","shell.execute_reply.started":"2022-11-24T03:42:29.900669Z","shell.execute_reply":"2022-11-24T03:42:29.907096Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"model = DistillBERTClass()\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-11-24T03:42:31.029550Z","iopub.execute_input":"2022-11-24T03:42:31.029902Z","iopub.status.idle":"2022-11-24T03:42:32.325061Z","shell.execute_reply.started":"2022-11-24T03:42:31.029871Z","shell.execute_reply":"2022-11-24T03:42:32.323956Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_transform.bias']\n- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"DistillBERTClass(\n  (l1): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0): TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (1): TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (2): TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (3): TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (4): TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (5): TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (dropout): Dropout(p=0.3, inplace=False)\n  (classifier): Linear(in_features=768, out_features=4, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Creating the loss function and optimizer\nloss_function = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)","metadata":{"execution":{"iopub.status.busy":"2022-11-24T03:42:36.408380Z","iopub.execute_input":"2022-11-24T03:42:36.409060Z","iopub.status.idle":"2022-11-24T03:42:36.414896Z","shell.execute_reply.started":"2022-11-24T03:42:36.409022Z","shell.execute_reply":"2022-11-24T03:42:36.413605Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# Function to calcuate the accuracy of the model\n\ndef calcuate_accu(big_idx, targets):\n    n_correct = (big_idx==targets).sum().item()\n    return n_correct","metadata":{"execution":{"iopub.status.busy":"2022-11-24T03:42:37.593049Z","iopub.execute_input":"2022-11-24T03:42:37.593423Z","iopub.status.idle":"2022-11-24T03:42:37.599740Z","shell.execute_reply.started":"2022-11-24T03:42:37.593390Z","shell.execute_reply":"2022-11-24T03:42:37.598423Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"# Defining the training function on the 80% of the dataset for tuning the distilbert model\n\ndef train(epoch):\n    tr_loss = 0\n    n_correct = 0\n    nb_tr_steps = 0\n    nb_tr_examples = 0\n    model.train()\n    for _,data in enumerate(training_loader, 0):\n        ids = data['ids'].to(device, dtype = torch.long)\n        mask = data['mask'].to(device, dtype = torch.long)\n        targets = data['targets'].to(device, dtype = torch.long)\n\n        outputs = model(ids, mask)\n        loss = loss_function(outputs, targets)\n        tr_loss += loss.item()\n        big_val, big_idx = torch.max(outputs.data, dim=1)\n        n_correct += calcuate_accu(big_idx, targets)\n\n        nb_tr_steps += 1\n        nb_tr_examples+=targets.size(0)\n        \n        if _%5000==0:\n            loss_step = tr_loss/nb_tr_steps\n            accu_step = (n_correct*100)/nb_tr_examples \n            print(f\"Training Loss per 5000 steps: {loss_step}\")\n            print(f\"Training Accuracy per 5000 steps: {accu_step}\")\n\n        optimizer.zero_grad()\n        loss.backward()\n        # # When using GPU\n        optimizer.step()\n\n    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}')\n    epoch_loss = tr_loss/nb_tr_steps\n    epoch_accu = (n_correct*100)/nb_tr_examples\n    print(f\"Training Loss Epoch: {epoch_loss}\")\n    print(f\"Training Accuracy Epoch: {epoch_accu}\")\n\n    return ","metadata":{"execution":{"iopub.status.busy":"2022-11-24T03:42:38.741170Z","iopub.execute_input":"2022-11-24T03:42:38.741870Z","iopub.status.idle":"2022-11-24T03:42:38.758180Z","shell.execute_reply.started":"2022-11-24T03:42:38.741834Z","shell.execute_reply":"2022-11-24T03:42:38.757096Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"for epoch in range(EPOCHS):\n    train(epoch)","metadata":{"execution":{"iopub.status.busy":"2022-11-24T03:42:39.560540Z","iopub.execute_input":"2022-11-24T03:42:39.560905Z","iopub.status.idle":"2022-11-24T03:47:21.433728Z","shell.execute_reply.started":"2022-11-24T03:42:39.560876Z","shell.execute_reply":"2022-11-24T03:47:21.432676Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  FutureWarning,\n","output_type":"stream"},{"name":"stdout","text":"Training Loss per 5000 steps: 1.3517279624938965\nTraining Accuracy per 5000 steps: 50.0\nThe Total Accuracy for Epoch 0: 83.07442196531792\nTraining Loss Epoch: 0.4042988758617635\nTraining Accuracy Epoch: 83.07442196531792\n","output_type":"stream"}]},{"cell_type":"code","source":"def valid(model, testing_loader):\n    model.eval()\n    n_correct = 0; n_wrong = 0; total = 0; tr_loss = 0\n    nb_tr_steps = 0\n    nb_tr_examples = 0\n    with torch.no_grad():\n        for _, data in enumerate(testing_loader, 0):\n            ids = data['ids'].to(device, dtype = torch.long)\n            mask = data['mask'].to(device, dtype = torch.long)\n            targets = data['targets'].to(device, dtype = torch.long)\n            outputs = model(ids, mask).squeeze()\n            loss = loss_function(outputs, targets)\n            tr_loss += loss.item()\n            big_val, big_idx = torch.max(outputs.data, dim=1)\n            n_correct += calcuate_accu(big_idx, targets)\n\n            nb_tr_steps += 1\n            nb_tr_examples+=targets.size(0)\n            \n            if _%5000==0:\n                loss_step = tr_loss/nb_tr_steps\n                accu_step = (n_correct*100)/nb_tr_examples\n                print(f\"Validation Loss per 100 steps: {loss_step}\")\n                print(f\"Validation Accuracy per 100 steps: {accu_step}\")\n    epoch_loss = tr_loss/nb_tr_steps\n    epoch_accu = (n_correct*100)/nb_tr_examples\n    print(f\"Validation Loss Epoch: {epoch_loss}\")\n    print(f\"Validation Accuracy Epoch: {epoch_accu}\")\n    \n    return epoch_accu\n","metadata":{"execution":{"iopub.status.busy":"2022-11-24T04:19:18.481358Z","iopub.execute_input":"2022-11-24T04:19:18.481718Z","iopub.status.idle":"2022-11-24T04:19:18.494183Z","shell.execute_reply.started":"2022-11-24T04:19:18.481688Z","shell.execute_reply":"2022-11-24T04:19:18.493060Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"print('This is the validation section to print the accuracy and see how it performs')\nprint('Here we are leveraging on the dataloader crearted for the validation dataset, the approcah is using more of pytorch')\n\nacc = valid(model, testing_loader)\nprint(\"Accuracy on test data = %0.2f%%\" % acc)","metadata":{"execution":{"iopub.status.busy":"2022-11-24T04:19:18.862886Z","iopub.execute_input":"2022-11-24T04:19:18.863285Z","iopub.status.idle":"2022-11-24T04:19:46.877570Z","shell.execute_reply.started":"2022-11-24T04:19:18.863243Z","shell.execute_reply":"2022-11-24T04:19:46.876454Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"This is the validation section to print the accuracy and see how it performs\nHere we are leveraging on the dataloader crearted for the validation dataset, the approcah is using more of pytorch\nValidation Loss per 100 steps: 0.2589256763458252\nValidation Accuracy per 100 steps: 100.0\nValidation Loss Epoch: 0.2728010421925671\nValidation Accuracy Epoch: 88.65606936416185\nAccuracy on test data = 88.66%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Load emotions data","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\nemotions = load_dataset(\"emotion\")\nemotions","metadata":{"execution":{"iopub.status.busy":"2022-11-24T03:10:37.111203Z","iopub.execute_input":"2022-11-24T03:10:37.111622Z","iopub.status.idle":"2022-11-24T03:10:48.257010Z","shell.execute_reply.started":"2022-11-24T03:10:37.111535Z","shell.execute_reply":"2022-11-24T03:10:48.255974Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/1.66k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebba49e4a9124fad8ee43ec7e5b1f7d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/1.61k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71caefced3984307ad4dc53612d944d0"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset emotion/default (download: 1.97 MiB, generated: 2.07 MiB, post-processed: Unknown size, total: 4.05 MiB) to /root/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/1.66M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67bf17f84b2a4d30a0e131ea5fe3cc07"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/204k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b10bab3aab44d05bdb7fa274004d7ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/207k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e6329988ea2435b950c41af7f344117"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/16000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset emotion downloaded and prepared to /root/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1cd265b569b64dcb97a0a070858a3fe0"}},"metadata":{}},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 16000\n    })\n    validation: Dataset({\n        features: ['text', 'label'],\n        num_rows: 2000\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 2000\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"### Load tokenizer","metadata":{}},{"cell_type":"code","source":"# load tokenizer from AutoTokenizer\nfrom transformers import AutoTokenizer\nmodel_ckpt = \"distilbert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(model_ckpt)","metadata":{"execution":{"iopub.status.busy":"2022-11-24T03:11:37.701602Z","iopub.execute_input":"2022-11-24T03:11:37.703110Z","iopub.status.idle":"2022-11-24T03:11:41.196929Z","shell.execute_reply.started":"2022-11-24T03:11:37.703065Z","shell.execute_reply":"2022-11-24T03:11:41.195796Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17300c497f21439ca9a9fcc5f7512a34"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfa6da42117e49e6934871fa650f1905"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db70b2bde8a24b8f906c87f32a04551d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0fa573ce72d44bc83eff6c5619b38f7"}},"metadata":{}}]},{"cell_type":"code","source":"def tokenize(batch):\n    return tokenizer(batch[\"text\"], padding=True, truncation=True)","metadata":{"execution":{"iopub.status.busy":"2022-11-24T03:12:32.467362Z","iopub.execute_input":"2022-11-24T03:12:32.467770Z","iopub.status.idle":"2022-11-24T03:12:32.473147Z","shell.execute_reply.started":"2022-11-24T03:12:32.467722Z","shell.execute_reply":"2022-11-24T03:12:32.471926Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"emotions_encoded = emotions.map(tokenize, batched=True, batch_size=None)\nemotions_encoded.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\nemotions_encoded","metadata":{"execution":{"iopub.status.busy":"2022-11-24T03:13:32.680448Z","iopub.execute_input":"2022-11-24T03:13:32.681447Z","iopub.status.idle":"2022-11-24T03:13:35.019306Z","shell.execute_reply.started":"2022-11-24T03:13:32.681409Z","shell.execute_reply":"2022-11-24T03:13:35.018168Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"932d98465e3742b79afdf8b199a9ce33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0aca92aca5c04037ba2f909f7dc50b7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8cbfe957086a489cb134924c215a840f"}},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label', 'input_ids', 'attention_mask'],\n        num_rows: 16000\n    })\n    validation: Dataset({\n        features: ['text', 'label', 'input_ids', 'attention_mask'],\n        num_rows: 2000\n    })\n    test: Dataset({\n        features: ['text', 'label', 'input_ids', 'attention_mask'],\n        num_rows: 2000\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"emotions_encoded[\"train\"][:3]","metadata":{"execution":{"iopub.status.busy":"2022-11-24T03:14:12.970529Z","iopub.execute_input":"2022-11-24T03:14:12.971019Z","iopub.status.idle":"2022-11-24T03:14:12.985585Z","shell.execute_reply.started":"2022-11-24T03:14:12.970980Z","shell.execute_reply":"2022-11-24T03:14:12.984300Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"{'label': tensor([0, 0, 3]),\n 'input_ids': tensor([[  101,  1045,  2134,  2102,  2514, 26608,   102,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0],\n         [  101,  1045,  2064,  2175,  2013,  3110,  2061, 20625,  2000,  2061,\n           9636, 17772,  2074,  2013,  2108,  2105,  2619,  2040, 14977,  1998,\n           2003,  8300,   102,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0],\n         [  101, 10047,  9775,  1037,  3371,  2000,  2695,  1045,  2514, 20505,\n           3308,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0]]),\n 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModel\n\nmodel_ckpt = \"distilbert-base-uncased\"\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = AutoModel.from_pretrained(model_ckpt).to(device)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-21T21:05:15.173541Z","iopub.execute_input":"2022-11-21T21:05:15.174225Z","iopub.status.idle":"2022-11-21T21:05:32.431340Z","shell.execute_reply.started":"2022-11-21T21:05:15.174187Z","shell.execute_reply":"2022-11-21T21:05:32.430229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-11-21T21:10:23.810354Z","iopub.execute_input":"2022-11-21T21:10:23.810830Z","iopub.status.idle":"2022-11-21T21:10:23.818083Z","shell.execute_reply.started":"2022-11-21T21:10:23.810790Z","shell.execute_reply":"2022-11-21T21:10:23.816882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\nnum_labels = 6\nmodel_ckpt = \"distilbert-base-uncased\"\nmodel = AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=num_labels).to(device)","metadata":{"execution":{"iopub.status.busy":"2022-11-21T21:10:25.556899Z","iopub.execute_input":"2022-11-21T21:10:25.558023Z","iopub.status.idle":"2022-11-21T21:10:26.929473Z","shell.execute_reply.started":"2022-11-21T21:10:25.557983Z","shell.execute_reply":"2022-11-21T21:10:26.928381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score\n\ndef compute_metrics(pred):\n    labels = pred.label_ids\n    preds = pred.prediction.argmax(-1)\n    f1 = f1_score(labels, preds, average=\"weighted\")\n    acc = accuracy_score(labels, preds)\n    return {\"accuracy\": acc, \"f1\": f1}","metadata":{"execution":{"iopub.status.busy":"2022-11-21T21:11:16.220940Z","iopub.execute_input":"2022-11-21T21:11:16.222086Z","iopub.status.idle":"2022-11-21T21:11:16.229316Z","shell.execute_reply.started":"2022-11-21T21:11:16.222032Z","shell.execute_reply":"2022-11-21T21:11:16.227713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Extracting the last hidden states","metadata":{}},{"cell_type":"code","source":"text = \"this is a test\"\ninputs = tokenizer(text, return_tensors=\"pt\")\nprint(f\"Input tensor shape: {inputs['input_ids'].size()}\")\nprint(inputs)","metadata":{"execution":{"iopub.status.busy":"2022-11-21T21:05:32.434377Z","iopub.execute_input":"2022-11-21T21:05:32.435166Z","iopub.status.idle":"2022-11-21T21:05:32.442911Z","shell.execute_reply.started":"2022-11-21T21:05:32.435121Z","shell.execute_reply":"2022-11-21T21:05:32.441824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = {k:v.to(device) for k,v in inputs.items()}\nprint(inputs)\nwith torch.no_grad():\n    outputs = model(**inputs)\nprint(outputs)","metadata":{"execution":{"iopub.status.busy":"2022-11-21T21:05:32.446997Z","iopub.execute_input":"2022-11-21T21:05:32.447334Z","iopub.status.idle":"2022-11-21T21:05:34.011297Z","shell.execute_reply.started":"2022-11-21T21:05:32.447307Z","shell.execute_reply":"2022-11-21T21:05:34.009213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outputs.last_hidden_state.size()","metadata":{"execution":{"iopub.status.busy":"2022-11-21T21:05:34.012917Z","iopub.execute_input":"2022-11-21T21:05:34.013304Z","iopub.status.idle":"2022-11-21T21:05:34.023308Z","shell.execute_reply.started":"2022-11-21T21:05:34.013268Z","shell.execute_reply":"2022-11-21T21:05:34.022153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outputs.last_hidden_state[:, 0].size()","metadata":{"execution":{"iopub.status.busy":"2022-11-21T21:05:34.024877Z","iopub.execute_input":"2022-11-21T21:05:34.026027Z","iopub.status.idle":"2022-11-21T21:05:34.033485Z","shell.execute_reply.started":"2022-11-21T21:05:34.025982Z","shell.execute_reply":"2022-11-21T21:05:34.032242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_hidden_states(batch):\n    # place model inputs on the GPU\n    inputs = {k:v.to(device) for k, v in batch.items() if k in tokenizer.model_input_names}\n    with torch.no_grad():\n        last_hidden_state = model(**inputs).last_hidden_state\n    return {\"hidden_state\": last_hidden_state[:, 0].cpu().numpy()}","metadata":{"execution":{"iopub.status.busy":"2022-11-21T21:05:34.038108Z","iopub.execute_input":"2022-11-21T21:05:34.039186Z","iopub.status.idle":"2022-11-21T21:05:34.046120Z","shell.execute_reply.started":"2022-11-21T21:05:34.039146Z","shell.execute_reply":"2022-11-21T21:05:34.044923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotions_encoded.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])","metadata":{"execution":{"iopub.status.busy":"2022-11-21T21:05:34.047823Z","iopub.execute_input":"2022-11-21T21:05:34.048438Z","iopub.status.idle":"2022-11-21T21:05:34.058257Z","shell.execute_reply.started":"2022-11-21T21:05:34.048389Z","shell.execute_reply":"2022-11-21T21:05:34.057216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotions_hidden = emotions_encoded.map(extract_hidden_states, batched=True)","metadata":{"execution":{"iopub.status.busy":"2022-11-21T21:05:45.548407Z","iopub.execute_input":"2022-11-21T21:05:45.548827Z","iopub.status.idle":"2022-11-21T21:06:31.471517Z","shell.execute_reply.started":"2022-11-21T21:05:45.548789Z","shell.execute_reply":"2022-11-21T21:06:31.470559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotions_hidden[\"train\"][\"hidden_state\"].shape","metadata":{"execution":{"iopub.status.busy":"2022-11-21T21:06:38.665942Z","iopub.execute_input":"2022-11-21T21:06:38.666332Z","iopub.status.idle":"2022-11-21T21:06:38.821862Z","shell.execute_reply.started":"2022-11-21T21:06:38.666299Z","shell.execute_reply":"2022-11-21T21:06:38.820800Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nX_train = np.array(emotions_hidden[\"train\"][\"hidden_state\"])\nX_valid = np.array(emotions_hidden[\"validation\"][\"hidden_state\"])\ny_train = np.array(emotions_hidden[\"train\"][\"label\"])\ny_valid = np.array(emotions_hidden[\"validation\"][\"label\"])\nprint(X_train.shape)\nprint(X_valid.shape)","metadata":{"execution":{"iopub.status.busy":"2022-11-21T21:06:41.648291Z","iopub.execute_input":"2022-11-21T21:06:41.648671Z","iopub.status.idle":"2022-11-21T21:06:41.827621Z","shell.execute_reply.started":"2022-11-21T21:06:41.648638Z","shell.execute_reply":"2022-11-21T21:06:41.826330Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Logistic Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlr_clf = LogisticRegression(max_iter=3000)\nlr_clf.fit(X_train, y_train)\nlr_clf.score(X_valid, y_valid)","metadata":{"execution":{"iopub.status.busy":"2022-11-21T21:06:44.623476Z","iopub.execute_input":"2022-11-21T21:06:44.623876Z","iopub.status.idle":"2022-11-21T21:09:29.675826Z","shell.execute_reply.started":"2022-11-21T21:06:44.623842Z","shell.execute_reply":"2022-11-21T21:09:29.674734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.dummy import DummyClassifier\ndummy_clf = DummyClassifier(strategy=\"most_frequent\")\ndummy_clf.fit(X_train, y_train)\ndummy_clf.score(X_valid, y_valid)","metadata":{"execution":{"iopub.status.busy":"2022-11-21T21:09:29.677943Z","iopub.execute_input":"2022-11-21T21:09:29.678927Z","iopub.status.idle":"2022-11-21T21:09:29.693814Z","shell.execute_reply.started":"2022-11-21T21:09:29.678889Z","shell.execute_reply":"2022-11-21T21:09:29.692343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\nimport matplotlib.pyplot as plt\n\ndef plot_confusion_matrix(y_preds, y_true, labels):\n    cm = confusion_matrix(y_true, y_preds, normalize=\"true\")\n    fig, ax = plt.subplots(figsize=(6, 6))\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n    disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n    plt.title(\"Normalized confusion matrix\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-21T21:09:29.700883Z","iopub.execute_input":"2022-11-21T21:09:29.704717Z","iopub.status.idle":"2022-11-21T21:09:29.718694Z","shell.execute_reply.started":"2022-11-21T21:09:29.704658Z","shell.execute_reply":"2022-11-21T21:09:29.716827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_preds = lr_clf.predict(X_valid)\nlabels = emotions[\"train\"].features[\"label\"].names\nplot_confusion_matrix(y_preds, y_valid, labels)","metadata":{"execution":{"iopub.status.busy":"2022-11-21T21:09:29.727409Z","iopub.execute_input":"2022-11-21T21:09:29.731100Z","iopub.status.idle":"2022-11-21T21:09:30.146649Z","shell.execute_reply.started":"2022-11-21T21:09:29.731039Z","shell.execute_reply":"2022-11-21T21:09:30.145700Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fine-tuning transformer","metadata":{}},{"cell_type":"code","source":"# from huggingface_hub import notebook_login\n# notebook_login()","metadata":{"execution":{"iopub.status.busy":"2022-11-21T02:42:51.601146Z","iopub.execute_input":"2022-11-21T02:42:51.601518Z","iopub.status.idle":"2022-11-21T02:42:51.637105Z","shell.execute_reply.started":"2022-11-21T02:42:51.601488Z","shell.execute_reply":"2022-11-21T02:42:51.636092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments\n\nbatch_size = 64\nlogging_steps = len(emotions_encoded[\"train\"])\nmodel_name = f\"{model_ckpt}-finetuned-emotion\"\ntraining_args = TrainingArguments(\n    output_dir=model_name,\n    num_train_epochs=2,\n    learning_rate=2e-5,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    weight_decay=0.01,\n    evaluation_strategy=\"epoch\",\n    disable_tqdm=False,\n    logging_steps=logging_steps,\n    push_to_hub=False,\n)","metadata":{"execution":{"iopub.status.busy":"2022-11-21T21:12:24.888380Z","iopub.execute_input":"2022-11-21T21:12:24.888800Z","iopub.status.idle":"2022-11-21T21:12:30.050218Z","shell.execute_reply.started":"2022-11-21T21:12:24.888756Z","shell.execute_reply":"2022-11-21T21:12:30.049222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    compute_metrics=compute_metrics,\n    train_dataset=emotions_encoded[\"train\"],\n    eval_dataset=emotions_encoded[\"validation\"],\n    tokenizer=tokenizer\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2022-11-21T21:12:35.710533Z","iopub.execute_input":"2022-11-21T21:12:35.711306Z","iopub.status.idle":"2022-11-21T21:14:23.458384Z","shell.execute_reply.started":"2022-11-21T21:12:35.711265Z","shell.execute_reply":"2022-11-21T21:14:23.456532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}