{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport transformers\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import DistilBertModel, DistilBertTokenizer","metadata":{"execution":{"iopub.status.busy":"2022-11-25T03:32:03.898511Z","iopub.execute_input":"2022-11-25T03:32:03.898927Z","iopub.status.idle":"2022-11-25T03:32:06.267186Z","shell.execute_reply.started":"2022-11-25T03:32:03.898843Z","shell.execute_reply":"2022-11-25T03:32:06.265882Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from torch import cuda\ndevice = \"cuda\" if cuda.is_available() else \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2022-11-25T03:32:06.269891Z","iopub.execute_input":"2022-11-25T03:32:06.270874Z","iopub.status.idle":"2022-11-25T03:32:06.383427Z","shell.execute_reply.started":"2022-11-25T03:32:06.270835Z","shell.execute_reply":"2022-11-25T03:32:06.382280Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"MAX_LEN = 512\nTRAIN_BATCH_SIZE = 4\nVALID_BATCH_SIZE = 2\nEPOCHS = 5\nLEARNING_RATE = 1e-05","metadata":{"execution":{"iopub.status.busy":"2022-11-25T03:32:06.385203Z","iopub.execute_input":"2022-11-25T03:32:06.386073Z","iopub.status.idle":"2022-11-25T03:32:06.394722Z","shell.execute_reply.started":"2022-11-25T03:32:06.386033Z","shell.execute_reply":"2022-11-25T03:32:06.393687Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv', delimiter='\\t', header=None)","metadata":{"execution":{"iopub.status.busy":"2022-11-25T03:32:06.397816Z","iopub.execute_input":"2022-11-25T03:32:06.398545Z","iopub.status.idle":"2022-11-25T03:32:07.025900Z","shell.execute_reply.started":"2022-11-25T03:32:06.398502Z","shell.execute_reply":"2022-11-25T03:32:07.024929Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print(df.head())\nprint(df.shape)","metadata":{"execution":{"iopub.status.busy":"2022-11-25T03:32:07.027558Z","iopub.execute_input":"2022-11-25T03:32:07.027915Z","iopub.status.idle":"2022-11-25T03:32:07.045447Z","shell.execute_reply.started":"2022-11-25T03:32:07.027879Z","shell.execute_reply":"2022-11-25T03:32:07.044170Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"                                                   0  1\n0  a stirring , funny and finally transporting re...  1\n1  apparently reassembled from the cutting room f...  0\n2  they presume their audience wo n't sit still f...  0\n3  this is a visually stunning rumination on love...  1\n4  jonathan parker 's bartleby should have been t...  1\n(6920, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoTokenizer\nmodel_ckpt = \"distilbert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(model_ckpt)","metadata":{"execution":{"iopub.status.busy":"2022-11-25T03:32:15.906311Z","iopub.execute_input":"2022-11-25T03:32:15.906723Z","iopub.status.idle":"2022-11-25T03:32:18.560174Z","shell.execute_reply.started":"2022-11-25T03:32:15.906690Z","shell.execute_reply":"2022-11-25T03:32:18.559006Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47e59034c89248c0a504af7203caa011"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0499e474a45e474ca8865756927898c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3051f2bb847045adb1d8b6c27990784f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d78052ef40474de287bc793f2b059e50"}},"metadata":{}}]},{"cell_type":"code","source":"class Triage(Dataset):\n    def __init__(self, dataframe, tokenizer, max_len):\n        self.len = len(dataframe)\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        \n    def __getitem__(self, index):   # index!\n        text = self.data.iloc[index, 0]\n        inputs = self.tokenizer.encode_plus(\n            text,\n            None,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            pad_to_max_length=True,\n            return_token_type_ids=True,\n            truncation=True\n        )\n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']\n\n        return {\n            'ids': torch.tensor(ids, dtype=torch.long),\n            'mask': torch.tensor(mask, dtype=torch.long),\n            'targets': torch.tensor(self.data.iloc[index, 1], dtype=torch.long)\n        } \n    \n    def __len__(self):\n        return self.len","metadata":{"execution":{"iopub.status.busy":"2022-11-25T03:32:46.886559Z","iopub.execute_input":"2022-11-25T03:32:46.887010Z","iopub.status.idle":"2022-11-25T03:32:46.898555Z","shell.execute_reply.started":"2022-11-25T03:32:46.886971Z","shell.execute_reply":"2022-11-25T03:32:46.897036Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_size = 0.8\ntrain_dataset = df.sample(frac=train_size,random_state=200)\ntest_dataset = df.drop(train_dataset.index)\ntrain_dataset = train_dataset.reset_index(drop=True)\ntest_dataset = test_dataset.reset_index(drop=True)\n\nprint(\"FULL Dataset: {}\".format(df.shape))\nprint(\"TRAIN Dataset: {}\".format(train_dataset.shape))\nprint(\"TEST Dataset: {}\".format(test_dataset.shape))\n\ntraining_set = Triage(train_dataset, tokenizer, MAX_LEN)\ntesting_set = Triage(test_dataset, tokenizer, MAX_LEN)","metadata":{"execution":{"iopub.status.busy":"2022-11-25T03:35:10.477156Z","iopub.execute_input":"2022-11-25T03:35:10.477533Z","iopub.status.idle":"2022-11-25T03:35:10.493397Z","shell.execute_reply.started":"2022-11-25T03:35:10.477502Z","shell.execute_reply":"2022-11-25T03:35:10.491967Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"FULL Dataset: (6920, 2)\nTRAIN Dataset: (5536, 2)\nTEST Dataset: (1384, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"train_params = {\n    'batch_size': TRAIN_BATCH_SIZE,\n    'shuffle': True,\n    'num_workers': 0\n}\n\ntest_params = {\n    'batch_size': VALID_BATCH_SIZE,\n    'shuffle': True,\n    'num_workers': 0\n}\n\ntraining_loader = DataLoader(training_set, **train_params)\ntesting_loader = DataLoader(testing_set, **test_params)","metadata":{"execution":{"iopub.status.busy":"2022-11-25T03:36:00.422286Z","iopub.execute_input":"2022-11-25T03:36:00.423194Z","iopub.status.idle":"2022-11-25T03:36:00.429902Z","shell.execute_reply.started":"2022-11-25T03:36:00.423145Z","shell.execute_reply":"2022-11-25T03:36:00.428837Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class DistillBERTClass(torch.nn.Module):\n    def __init__(self):\n        super(DistillBERTClass, self).__init__()\n        self.l1 = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n        self.pre_classifier = torch.nn.Linear(768, 768)\n        self.dropout = torch.nn.Dropout(0.3)\n        self.classifier = torch.nn.Linear(768, 4)\n\n    def forward(self, input_ids, attention_mask):\n        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n        hidden_state = output_1[0]\n        pooler = hidden_state[:, 0]\n        pooler = self.pre_classifier(pooler)\n        pooler = torch.nn.ReLU()(pooler)\n        pooler = self.dropout(pooler)\n        output = self.classifier(pooler)\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-11-25T03:36:20.794682Z","iopub.execute_input":"2022-11-25T03:36:20.795077Z","iopub.status.idle":"2022-11-25T03:36:20.803008Z","shell.execute_reply.started":"2022-11-25T03:36:20.795044Z","shell.execute_reply":"2022-11-25T03:36:20.801922Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model = DistillBERTClass()\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-11-25T03:36:23.406013Z","iopub.execute_input":"2022-11-25T03:36:23.406389Z","iopub.status.idle":"2022-11-25T03:36:37.593241Z","shell.execute_reply.started":"2022-11-25T03:36:23.406350Z","shell.execute_reply":"2022-11-25T03:36:37.592315Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/256M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d0b6918d45244b6b87b48b2d82e6e1f"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"DistillBERTClass(\n  (l1): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0): TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (1): TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (2): TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (3): TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (4): TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (5): TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (dropout): Dropout(p=0.3, inplace=False)\n  (classifier): Linear(in_features=768, out_features=4, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Creating the loss function and optimizer\nloss_function = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)","metadata":{"execution":{"iopub.status.busy":"2022-11-25T03:36:46.216876Z","iopub.execute_input":"2022-11-25T03:36:46.217243Z","iopub.status.idle":"2022-11-25T03:36:46.223277Z","shell.execute_reply.started":"2022-11-25T03:36:46.217210Z","shell.execute_reply":"2022-11-25T03:36:46.222114Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Function to calcuate the accuracy of the model\ndef calcuate_accu(big_idx, targets):\n    n_correct = (big_idx==targets).sum().item()\n    return n_correct","metadata":{"execution":{"iopub.status.busy":"2022-11-25T03:36:50.931598Z","iopub.execute_input":"2022-11-25T03:36:50.932072Z","iopub.status.idle":"2022-11-25T03:36:50.937502Z","shell.execute_reply.started":"2022-11-25T03:36:50.932025Z","shell.execute_reply":"2022-11-25T03:36:50.936522Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Defining the training function on the 80% of the dataset for tuning the distilbert model\n\ndef train(epoch):\n    tr_loss = 0\n    n_correct = 0\n    nb_tr_steps = 0\n    nb_tr_examples = 0\n    model.train()\n    for _,data in enumerate(training_loader, 0):\n        ids = data['ids'].to(device, dtype = torch.long)\n        mask = data['mask'].to(device, dtype = torch.long)\n        targets = data['targets'].to(device, dtype = torch.long)\n\n        outputs = model(ids, mask)\n        loss = loss_function(outputs, targets)\n        tr_loss += loss.item()\n        big_val, big_idx = torch.max(outputs.data, dim=1)\n        n_correct += calcuate_accu(big_idx, targets)\n\n        nb_tr_steps += 1\n        nb_tr_examples+=targets.size(0)\n        \n        if _%5000==0:\n            loss_step = tr_loss/nb_tr_steps\n            accu_step = (n_correct*100)/nb_tr_examples \n            print(f\"Training Loss per 5000 steps: {loss_step}\")\n            print(f\"Training Accuracy per 5000 steps: {accu_step}\")\n\n        optimizer.zero_grad()\n        loss.backward()\n        # # When using GPU\n        optimizer.step()\n\n    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}')\n    epoch_loss = tr_loss/nb_tr_steps\n    epoch_accu = (n_correct*100)/nb_tr_examples\n    print(f\"Training Loss Epoch: {epoch_loss}\")\n    print(f\"Training Accuracy Epoch: {epoch_accu}\")\n\n    return ","metadata":{"execution":{"iopub.status.busy":"2022-11-25T03:36:53.060319Z","iopub.execute_input":"2022-11-25T03:36:53.060780Z","iopub.status.idle":"2022-11-25T03:36:53.086194Z","shell.execute_reply.started":"2022-11-25T03:36:53.060744Z","shell.execute_reply":"2022-11-25T03:36:53.085043Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"for epoch in range(EPOCHS):\n    train(epoch)","metadata":{"execution":{"iopub.status.busy":"2022-11-25T03:36:55.487565Z","iopub.execute_input":"2022-11-25T03:36:55.488308Z","iopub.status.idle":"2022-11-25T03:59:09.301736Z","shell.execute_reply.started":"2022-11-25T03:36:55.488265Z","shell.execute_reply":"2022-11-25T03:59:09.298239Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  FutureWarning,\n","output_type":"stream"},{"name":"stdout","text":"Training Loss per 5000 steps: 1.3615832328796387\nTraining Accuracy per 5000 steps: 50.0\nThe Total Accuracy for Epoch 0: 83.14667630057804\nTraining Loss Epoch: 0.40562261505499264\nTraining Accuracy Epoch: 83.14667630057804\nTraining Loss per 5000 steps: 0.04588167369365692\nTraining Accuracy per 5000 steps: 100.0\nThe Total Accuracy for Epoch 1: 93.31647398843931\nTraining Loss Epoch: 0.1802129774321425\nTraining Accuracy Epoch: 93.31647398843931\nTraining Loss per 5000 steps: 0.22847843170166016\nTraining Accuracy per 5000 steps: 75.0\nThe Total Accuracy for Epoch 2: 97.10982658959537\nTraining Loss Epoch: 0.08367190323786869\nTraining Accuracy Epoch: 97.10982658959537\nTraining Loss per 5000 steps: 0.006320134270936251\nTraining Accuracy per 5000 steps: 100.0\nThe Total Accuracy for Epoch 3: 98.46459537572254\nTraining Loss Epoch: 0.047927870845820515\nTraining Accuracy Epoch: 98.46459537572254\nTraining Loss per 5000 steps: 0.006167694926261902\nTraining Accuracy per 5000 steps: 100.0\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_24/361968077.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_24/2012505160.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# # When using GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    151\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                    \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                    maximize=group['maximize'])\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"def valid(model, testing_loader):\n    model.eval()\n    n_correct = 0; n_wrong = 0; total = 0; tr_loss = 0\n    nb_tr_steps = 0\n    nb_tr_examples = 0\n    with torch.no_grad():\n        for _, data in enumerate(testing_loader, 0):\n            ids = data['ids'].to(device, dtype = torch.long)\n            mask = data['mask'].to(device, dtype = torch.long)\n            targets = data['targets'].to(device, dtype = torch.long)\n            outputs = model(ids, mask).squeeze()\n            loss = loss_function(outputs, targets)\n            tr_loss += loss.item()\n            big_val, big_idx = torch.max(outputs.data, dim=1)\n            n_correct += calcuate_accu(big_idx, targets)\n\n            nb_tr_steps += 1\n            nb_tr_examples+=targets.size(0)\n            \n            if _%5000==0:\n                loss_step = tr_loss/nb_tr_steps\n                accu_step = (n_correct*100)/nb_tr_examples\n                print(f\"Validation Loss per 100 steps: {loss_step}\")\n                print(f\"Validation Accuracy per 100 steps: {accu_step}\")\n    epoch_loss = tr_loss/nb_tr_steps\n    epoch_accu = (n_correct*100)/nb_tr_examples\n    print(f\"Validation Loss Epoch: {epoch_loss}\")\n    print(f\"Validation Accuracy Epoch: {epoch_accu}\")\n    \n    return epoch_accu\n","metadata":{"execution":{"iopub.status.busy":"2022-11-24T04:19:18.481358Z","iopub.execute_input":"2022-11-24T04:19:18.481718Z","iopub.status.idle":"2022-11-24T04:19:18.494183Z","shell.execute_reply.started":"2022-11-24T04:19:18.481688Z","shell.execute_reply":"2022-11-24T04:19:18.493060Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"print('This is the validation section to print the accuracy and see how it performs')\nprint('Here we are leveraging on the dataloader crearted for the validation dataset, the approcah is using more of pytorch')\n\nacc = valid(model, testing_loader)\nprint(\"Accuracy on test data = %0.2f%%\" % acc)","metadata":{"execution":{"iopub.status.busy":"2022-11-24T04:19:18.862886Z","iopub.execute_input":"2022-11-24T04:19:18.863285Z","iopub.status.idle":"2022-11-24T04:19:46.877570Z","shell.execute_reply.started":"2022-11-24T04:19:18.863243Z","shell.execute_reply":"2022-11-24T04:19:46.876454Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"This is the validation section to print the accuracy and see how it performs\nHere we are leveraging on the dataloader crearted for the validation dataset, the approcah is using more of pytorch\nValidation Loss per 100 steps: 0.2589256763458252\nValidation Accuracy per 100 steps: 100.0\nValidation Loss Epoch: 0.2728010421925671\nValidation Accuracy Epoch: 88.65606936416185\nAccuracy on test data = 88.66%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Load emotions data","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\nemotions = load_dataset(\"emotion\")\nemotions","metadata":{"execution":{"iopub.status.busy":"2022-11-25T03:59:09.304687Z","iopub.status.idle":"2022-11-25T03:59:09.306983Z","shell.execute_reply.started":"2022-11-25T03:59:09.306731Z","shell.execute_reply":"2022-11-25T03:59:09.306756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load tokenizer","metadata":{}},{"cell_type":"code","source":"# load tokenizer from AutoTokenizer\nfrom transformers import AutoTokenizer\nmodel_ckpt = \"distilbert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(model_ckpt)","metadata":{"execution":{"iopub.status.busy":"2022-11-24T03:11:37.701602Z","iopub.execute_input":"2022-11-24T03:11:37.703110Z","iopub.status.idle":"2022-11-24T03:11:41.196929Z","shell.execute_reply.started":"2022-11-24T03:11:37.703065Z","shell.execute_reply":"2022-11-24T03:11:41.195796Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17300c497f21439ca9a9fcc5f7512a34"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfa6da42117e49e6934871fa650f1905"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db70b2bde8a24b8f906c87f32a04551d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0fa573ce72d44bc83eff6c5619b38f7"}},"metadata":{}}]},{"cell_type":"code","source":"def tokenize(batch):\n    return tokenizer(batch[\"text\"], padding=True, truncation=True)","metadata":{"execution":{"iopub.status.busy":"2022-11-24T03:12:32.467362Z","iopub.execute_input":"2022-11-24T03:12:32.467770Z","iopub.status.idle":"2022-11-24T03:12:32.473147Z","shell.execute_reply.started":"2022-11-24T03:12:32.467722Z","shell.execute_reply":"2022-11-24T03:12:32.471926Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"emotions_encoded = emotions.map(tokenize, batched=True, batch_size=None)\nemotions_encoded.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\nemotions_encoded","metadata":{"execution":{"iopub.status.busy":"2022-11-24T03:13:32.680448Z","iopub.execute_input":"2022-11-24T03:13:32.681447Z","iopub.status.idle":"2022-11-24T03:13:35.019306Z","shell.execute_reply.started":"2022-11-24T03:13:32.681409Z","shell.execute_reply":"2022-11-24T03:13:35.018168Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"932d98465e3742b79afdf8b199a9ce33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0aca92aca5c04037ba2f909f7dc50b7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8cbfe957086a489cb134924c215a840f"}},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label', 'input_ids', 'attention_mask'],\n        num_rows: 16000\n    })\n    validation: Dataset({\n        features: ['text', 'label', 'input_ids', 'attention_mask'],\n        num_rows: 2000\n    })\n    test: Dataset({\n        features: ['text', 'label', 'input_ids', 'attention_mask'],\n        num_rows: 2000\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"emotions_encoded[\"train\"][:3]","metadata":{"execution":{"iopub.status.busy":"2022-11-24T03:14:12.970529Z","iopub.execute_input":"2022-11-24T03:14:12.971019Z","iopub.status.idle":"2022-11-24T03:14:12.985585Z","shell.execute_reply.started":"2022-11-24T03:14:12.970980Z","shell.execute_reply":"2022-11-24T03:14:12.984300Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"{'label': tensor([0, 0, 3]),\n 'input_ids': tensor([[  101,  1045,  2134,  2102,  2514, 26608,   102,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0],\n         [  101,  1045,  2064,  2175,  2013,  3110,  2061, 20625,  2000,  2061,\n           9636, 17772,  2074,  2013,  2108,  2105,  2619,  2040, 14977,  1998,\n           2003,  8300,   102,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0],\n         [  101, 10047,  9775,  1037,  3371,  2000,  2695,  1045,  2514, 20505,\n           3308,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0]]),\n 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModel\n\nmodel_ckpt = \"distilbert-base-uncased\"\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = AutoModel.from_pretrained(model_ckpt).to(device)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-21T21:05:15.173541Z","iopub.execute_input":"2022-11-21T21:05:15.174225Z","iopub.status.idle":"2022-11-21T21:05:32.431340Z","shell.execute_reply.started":"2022-11-21T21:05:15.174187Z","shell.execute_reply":"2022-11-21T21:05:32.430229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-11-21T21:10:23.810354Z","iopub.execute_input":"2022-11-21T21:10:23.810830Z","iopub.status.idle":"2022-11-21T21:10:23.818083Z","shell.execute_reply.started":"2022-11-21T21:10:23.810790Z","shell.execute_reply":"2022-11-21T21:10:23.816882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\nnum_labels = 6\nmodel_ckpt = \"distilbert-base-uncased\"\nmodel = AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=num_labels).to(device)","metadata":{"execution":{"iopub.status.busy":"2022-11-21T21:10:25.556899Z","iopub.execute_input":"2022-11-21T21:10:25.558023Z","iopub.status.idle":"2022-11-21T21:10:26.929473Z","shell.execute_reply.started":"2022-11-21T21:10:25.557983Z","shell.execute_reply":"2022-11-21T21:10:26.928381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score\n\ndef compute_metrics(pred):\n    labels = pred.label_ids\n    preds = pred.prediction.argmax(-1)\n    f1 = f1_score(labels, preds, average=\"weighted\")\n    acc = accuracy_score(labels, preds)\n    return {\"accuracy\": acc, \"f1\": f1}","metadata":{"execution":{"iopub.status.busy":"2022-11-21T21:11:16.220940Z","iopub.execute_input":"2022-11-21T21:11:16.222086Z","iopub.status.idle":"2022-11-21T21:11:16.229316Z","shell.execute_reply.started":"2022-11-21T21:11:16.222032Z","shell.execute_reply":"2022-11-21T21:11:16.227713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Extracting the last hidden states","metadata":{}},{"cell_type":"code","source":"text = \"this is a test\"\ninputs = tokenizer(text, return_tensors=\"pt\")\nprint(f\"Input tensor shape: {inputs['input_ids'].size()}\")\nprint(inputs)","metadata":{"execution":{"iopub.status.busy":"2022-11-21T21:05:32.434377Z","iopub.execute_input":"2022-11-21T21:05:32.435166Z","iopub.status.idle":"2022-11-21T21:05:32.442911Z","shell.execute_reply.started":"2022-11-21T21:05:32.435121Z","shell.execute_reply":"2022-11-21T21:05:32.441824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = {k:v.to(device) for k,v in inputs.items()}\nprint(inputs)\nwith torch.no_grad():\n    outputs = model(**inputs)\nprint(outputs)","metadata":{"execution":{"iopub.status.busy":"2022-11-21T21:05:32.446997Z","iopub.execute_input":"2022-11-21T21:05:32.447334Z","iopub.status.idle":"2022-11-21T21:05:34.011297Z","shell.execute_reply.started":"2022-11-21T21:05:32.447307Z","shell.execute_reply":"2022-11-21T21:05:34.009213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outputs.last_hidden_state.size()","metadata":{"execution":{"iopub.status.busy":"2022-11-21T21:05:34.012917Z","iopub.execute_input":"2022-11-21T21:05:34.013304Z","iopub.status.idle":"2022-11-21T21:05:34.023308Z","shell.execute_reply.started":"2022-11-21T21:05:34.013268Z","shell.execute_reply":"2022-11-21T21:05:34.022153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outputs.last_hidden_state[:, 0].size()","metadata":{"execution":{"iopub.status.busy":"2022-11-21T21:05:34.024877Z","iopub.execute_input":"2022-11-21T21:05:34.026027Z","iopub.status.idle":"2022-11-21T21:05:34.033485Z","shell.execute_reply.started":"2022-11-21T21:05:34.025982Z","shell.execute_reply":"2022-11-21T21:05:34.032242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_hidden_states(batch):\n    # place model inputs on the GPU\n    inputs = {k:v.to(device) for k, v in batch.items() if k in tokenizer.model_input_names}\n    with torch.no_grad():\n        last_hidden_state = model(**inputs).last_hidden_state\n    return {\"hidden_state\": last_hidden_state[:, 0].cpu().numpy()}","metadata":{"execution":{"iopub.status.busy":"2022-11-21T21:05:34.038108Z","iopub.execute_input":"2022-11-21T21:05:34.039186Z","iopub.status.idle":"2022-11-21T21:05:34.046120Z","shell.execute_reply.started":"2022-11-21T21:05:34.039146Z","shell.execute_reply":"2022-11-21T21:05:34.044923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotions_encoded.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])","metadata":{"execution":{"iopub.status.busy":"2022-11-21T21:05:34.047823Z","iopub.execute_input":"2022-11-21T21:05:34.048438Z","iopub.status.idle":"2022-11-21T21:05:34.058257Z","shell.execute_reply.started":"2022-11-21T21:05:34.048389Z","shell.execute_reply":"2022-11-21T21:05:34.057216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotions_hidden = emotions_encoded.map(extract_hidden_states, batched=True)","metadata":{"execution":{"iopub.status.busy":"2022-11-21T21:05:45.548407Z","iopub.execute_input":"2022-11-21T21:05:45.548827Z","iopub.status.idle":"2022-11-21T21:06:31.471517Z","shell.execute_reply.started":"2022-11-21T21:05:45.548789Z","shell.execute_reply":"2022-11-21T21:06:31.470559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotions_hidden[\"train\"][\"hidden_state\"].shape","metadata":{"execution":{"iopub.status.busy":"2022-11-21T21:06:38.665942Z","iopub.execute_input":"2022-11-21T21:06:38.666332Z","iopub.status.idle":"2022-11-21T21:06:38.821862Z","shell.execute_reply.started":"2022-11-21T21:06:38.666299Z","shell.execute_reply":"2022-11-21T21:06:38.820800Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nX_train = np.array(emotions_hidden[\"train\"][\"hidden_state\"])\nX_valid = np.array(emotions_hidden[\"validation\"][\"hidden_state\"])\ny_train = np.array(emotions_hidden[\"train\"][\"label\"])\ny_valid = np.array(emotions_hidden[\"validation\"][\"label\"])\nprint(X_train.shape)\nprint(X_valid.shape)","metadata":{"execution":{"iopub.status.busy":"2022-11-21T21:06:41.648291Z","iopub.execute_input":"2022-11-21T21:06:41.648671Z","iopub.status.idle":"2022-11-21T21:06:41.827621Z","shell.execute_reply.started":"2022-11-21T21:06:41.648638Z","shell.execute_reply":"2022-11-21T21:06:41.826330Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Logistic Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlr_clf = LogisticRegression(max_iter=3000)\nlr_clf.fit(X_train, y_train)\nlr_clf.score(X_valid, y_valid)","metadata":{"execution":{"iopub.status.busy":"2022-11-21T21:06:44.623476Z","iopub.execute_input":"2022-11-21T21:06:44.623876Z","iopub.status.idle":"2022-11-21T21:09:29.675826Z","shell.execute_reply.started":"2022-11-21T21:06:44.623842Z","shell.execute_reply":"2022-11-21T21:09:29.674734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.dummy import DummyClassifier\ndummy_clf = DummyClassifier(strategy=\"most_frequent\")\ndummy_clf.fit(X_train, y_train)\ndummy_clf.score(X_valid, y_valid)","metadata":{"execution":{"iopub.status.busy":"2022-11-21T21:09:29.677943Z","iopub.execute_input":"2022-11-21T21:09:29.678927Z","iopub.status.idle":"2022-11-21T21:09:29.693814Z","shell.execute_reply.started":"2022-11-21T21:09:29.678889Z","shell.execute_reply":"2022-11-21T21:09:29.692343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\nimport matplotlib.pyplot as plt\n\ndef plot_confusion_matrix(y_preds, y_true, labels):\n    cm = confusion_matrix(y_true, y_preds, normalize=\"true\")\n    fig, ax = plt.subplots(figsize=(6, 6))\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n    disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n    plt.title(\"Normalized confusion matrix\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-21T21:09:29.700883Z","iopub.execute_input":"2022-11-21T21:09:29.704717Z","iopub.status.idle":"2022-11-21T21:09:29.718694Z","shell.execute_reply.started":"2022-11-21T21:09:29.704658Z","shell.execute_reply":"2022-11-21T21:09:29.716827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_preds = lr_clf.predict(X_valid)\nlabels = emotions[\"train\"].features[\"label\"].names\nplot_confusion_matrix(y_preds, y_valid, labels)","metadata":{"execution":{"iopub.status.busy":"2022-11-21T21:09:29.727409Z","iopub.execute_input":"2022-11-21T21:09:29.731100Z","iopub.status.idle":"2022-11-21T21:09:30.146649Z","shell.execute_reply.started":"2022-11-21T21:09:29.731039Z","shell.execute_reply":"2022-11-21T21:09:30.145700Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fine-tuning transformer","metadata":{}},{"cell_type":"code","source":"# from huggingface_hub import notebook_login\n# notebook_login()","metadata":{"execution":{"iopub.status.busy":"2022-11-21T02:42:51.601146Z","iopub.execute_input":"2022-11-21T02:42:51.601518Z","iopub.status.idle":"2022-11-21T02:42:51.637105Z","shell.execute_reply.started":"2022-11-21T02:42:51.601488Z","shell.execute_reply":"2022-11-21T02:42:51.636092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments\n\nbatch_size = 64\nlogging_steps = len(emotions_encoded[\"train\"])\nmodel_name = f\"{model_ckpt}-finetuned-emotion\"\ntraining_args = TrainingArguments(\n    output_dir=model_name,\n    num_train_epochs=2,\n    learning_rate=2e-5,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    weight_decay=0.01,\n    evaluation_strategy=\"epoch\",\n    disable_tqdm=False,\n    logging_steps=logging_steps,\n    push_to_hub=False,\n)","metadata":{"execution":{"iopub.status.busy":"2022-11-21T21:12:24.888380Z","iopub.execute_input":"2022-11-21T21:12:24.888800Z","iopub.status.idle":"2022-11-21T21:12:30.050218Z","shell.execute_reply.started":"2022-11-21T21:12:24.888756Z","shell.execute_reply":"2022-11-21T21:12:30.049222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    compute_metrics=compute_metrics,\n    train_dataset=emotions_encoded[\"train\"],\n    eval_dataset=emotions_encoded[\"validation\"],\n    tokenizer=tokenizer\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2022-11-21T21:12:35.710533Z","iopub.execute_input":"2022-11-21T21:12:35.711306Z","iopub.status.idle":"2022-11-21T21:14:23.458384Z","shell.execute_reply.started":"2022-11-21T21:12:35.711265Z","shell.execute_reply":"2022-11-21T21:14:23.456532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}