{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom transformers import AutoModel\n\nmodel_ckpt = \"distilbert-base-uncased\"\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = AutoModel.from_pretrained(model_ckpt).to(device)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-13T02:53:15.778095Z","iopub.execute_input":"2022-11-13T02:53:15.778578Z","iopub.status.idle":"2022-11-13T02:53:27.081036Z","shell.execute_reply.started":"2022-11-13T02:53:15.778540Z","shell.execute_reply":"2022-11-13T02:53:27.079974Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"839394cd226848b4bb7f99fe662c6e3e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/256M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"171167c5e65346c1b854336501242c00"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias']\n- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Extracting the last hidden states","metadata":{}},{"cell_type":"code","source":"# load tokenizer from AutoTokenizer\nfrom transformers import AutoTokenizer\nmodel_ckpt = \"distilbert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(model_ckpt)","metadata":{"execution":{"iopub.status.busy":"2022-11-13T02:58:11.539340Z","iopub.execute_input":"2022-11-13T02:58:11.539743Z","iopub.status.idle":"2022-11-13T02:58:17.998424Z","shell.execute_reply.started":"2022-11-13T02:58:11.539711Z","shell.execute_reply":"2022-11-13T02:58:17.997118Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c333496d3e2b40e28ca19f37be88b91e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9d030551d3546c9979efc1f714f9a36"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ee8c57da1694b0daa5f9916aed1a24b"}},"metadata":{}}]},{"cell_type":"code","source":"text = \"this is a test\"\ninputs = tokenizer(text, return_tensors=\"pt\")\nprint(f\"Input tensor shape: {inputs['input_ids'].size()}\")","metadata":{"execution":{"iopub.status.busy":"2022-11-13T02:58:22.049507Z","iopub.execute_input":"2022-11-13T02:58:22.049932Z","iopub.status.idle":"2022-11-13T02:58:22.066669Z","shell.execute_reply.started":"2022-11-13T02:58:22.049899Z","shell.execute_reply":"2022-11-13T02:58:22.065644Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Input tensor shape: torch.Size([1, 6])\n","output_type":"stream"}]},{"cell_type":"code","source":"inputs = {k:v.to(device) for k,v in inputs.items()}\nprint(inputs)\nwith torch.no_grad():\n    outputs = model(**inputs)\nprint(outputs)","metadata":{"execution":{"iopub.status.busy":"2022-11-13T03:00:14.359300Z","iopub.execute_input":"2022-11-13T03:00:14.359695Z","iopub.status.idle":"2022-11-13T03:00:14.391140Z","shell.execute_reply.started":"2022-11-13T03:00:14.359664Z","shell.execute_reply":"2022-11-13T03:00:14.390166Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"{'input_ids': tensor([[ 101, 2023, 2003, 1037, 3231,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}\nBaseModelOutput(last_hidden_state=tensor([[[-0.1565, -0.1862,  0.0528,  ..., -0.1188,  0.0662,  0.5470],\n         [-0.3575, -0.6484, -0.0618,  ..., -0.3040,  0.3508,  0.5221],\n         [-0.2772, -0.4459,  0.1818,  ..., -0.0948, -0.0076,  0.9958],\n         [-0.2841, -0.3917,  0.3753,  ..., -0.2151, -0.1173,  1.0526],\n         [ 0.2661, -0.5094, -0.3180,  ..., -0.4203,  0.0144, -0.2149],\n         [ 0.9441,  0.0112, -0.4714,  ...,  0.1439, -0.7288, -0.1619]]]), hidden_states=None, attentions=None)\n","output_type":"stream"}]},{"cell_type":"code","source":"outputs.last_hidden_state.size()","metadata":{"execution":{"iopub.status.busy":"2022-11-13T03:13:41.865929Z","iopub.execute_input":"2022-11-13T03:13:41.866402Z","iopub.status.idle":"2022-11-13T03:13:41.873995Z","shell.execute_reply.started":"2022-11-13T03:13:41.866365Z","shell.execute_reply":"2022-11-13T03:13:41.872831Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 6, 768])"},"metadata":{}}]},{"cell_type":"code","source":"outputs.last_hidden_state[:, 0].size()","metadata":{"execution":{"iopub.status.busy":"2022-11-13T03:14:24.585145Z","iopub.execute_input":"2022-11-13T03:14:24.585543Z","iopub.status.idle":"2022-11-13T03:14:24.593952Z","shell.execute_reply.started":"2022-11-13T03:14:24.585513Z","shell.execute_reply":"2022-11-13T03:14:24.592843Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 768])"},"metadata":{}}]},{"cell_type":"code","source":"def extract_hidden_states(batch):\n    # place model inputs on the GPU\n    inputs = {k:v.to(device) for k, v in batch.items() if k in tokenizer.model_input_names}\n    with torch.no_grad():\n        last_hidden_state = model(**inputs).last_hidden_state\n    return {\"hidden_state\": last_hidden_state[:, 0].cpu().numpy()}\n","metadata":{"execution":{"iopub.status.busy":"2022-11-13T03:18:58.551884Z","iopub.execute_input":"2022-11-13T03:18:58.552305Z","iopub.status.idle":"2022-11-13T03:18:58.559722Z","shell.execute_reply.started":"2022-11-13T03:18:58.552274Z","shell.execute_reply":"2022-11-13T03:18:58.558461Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}