{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datasets import load_dataset\nemotions = load_dataset(\"emotion\")\nemotions","metadata":{"execution":{"iopub.status.busy":"2022-11-20T20:37:11.661361Z","iopub.execute_input":"2022-11-20T20:37:11.662376Z","iopub.status.idle":"2022-11-20T20:37:21.615699Z","shell.execute_reply.started":"2022-11-20T20:37:11.662262Z","shell.execute_reply":"2022-11-20T20:37:21.614616Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/1.66k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52b36e1bbda2486596b91af08648d928"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/1.61k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b5d361d7808451092de37d2f8e51ed8"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset emotion/default (download: 1.97 MiB, generated: 2.07 MiB, post-processed: Unknown size, total: 4.05 MiB) to /root/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/1.66M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5a7ffa07deb47668e3d0ab86c7f2da2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/204k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a5b43554e844c62bcef94729248e26c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/207k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4540b7e4d4164c6a9b5d108fa1801cba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/16000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset emotion downloaded and prepared to /root/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a229324909d14d80a531b61b22aa7ff6"}},"metadata":{}},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 16000\n    })\n    validation: Dataset({\n        features: ['text', 'label'],\n        num_rows: 2000\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 2000\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"# load tokenizer from AutoTokenizer\nfrom transformers import AutoTokenizer\nmodel_ckpt = \"distilbert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(model_ckpt)","metadata":{"execution":{"iopub.status.busy":"2022-11-20T20:38:26.336640Z","iopub.execute_input":"2022-11-20T20:38:26.337046Z","iopub.status.idle":"2022-11-20T20:38:29.876682Z","shell.execute_reply.started":"2022-11-20T20:38:26.337010Z","shell.execute_reply":"2022-11-20T20:38:29.875497Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"714ec7a6944b4b2683ee594af19f86e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f252700f3ec42f98e447a61be7edfd9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c07f9f5c5eb4cc0b1cd7b91e7ae8d49"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"293d07961c194dcb9d4f937f4c0d88dd"}},"metadata":{}}]},{"cell_type":"code","source":"def tokenize(batch):\n    return tokenizer(batch[\"text\"], padding=True, truncation=True)","metadata":{"execution":{"iopub.status.busy":"2022-11-20T20:38:41.497050Z","iopub.execute_input":"2022-11-20T20:38:41.497854Z","iopub.status.idle":"2022-11-20T20:38:41.503574Z","shell.execute_reply.started":"2022-11-20T20:38:41.497812Z","shell.execute_reply":"2022-11-20T20:38:41.502037Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"emotions_encoded = emotions.map(tokenize, batched=True, batch_size=None)","metadata":{"execution":{"iopub.status.busy":"2022-11-20T20:38:42.401441Z","iopub.execute_input":"2022-11-20T20:38:42.401812Z","iopub.status.idle":"2022-11-20T20:38:44.958928Z","shell.execute_reply.started":"2022-11-20T20:38:42.401768Z","shell.execute_reply":"2022-11-20T20:38:44.957994Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa12b177dee546ccb56d899224867d47"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62327465f5a949a5b3a7647d8c5f36d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c909e966f394417cae870353b7aee3f8"}},"metadata":{}}]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModel\n\nmodel_ckpt = \"distilbert-base-uncased\"\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = AutoModel.from_pretrained(model_ckpt).to(device)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-20T20:39:05.015553Z","iopub.execute_input":"2022-11-20T20:39:05.015970Z","iopub.status.idle":"2022-11-20T20:39:28.412541Z","shell.execute_reply.started":"2022-11-20T20:39:05.015931Z","shell.execute_reply":"2022-11-20T20:39:28.411410Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/256M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8c61bf0c482466cad03647b8b0348ad"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias']\n- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Extracting the last hidden states","metadata":{}},{"cell_type":"code","source":"text = \"this is a test\"\ninputs = tokenizer(text, return_tensors=\"pt\")\nprint(f\"Input tensor shape: {inputs['input_ids'].size()}\")\nprint(inputs)","metadata":{"execution":{"iopub.status.busy":"2022-11-20T20:39:38.158580Z","iopub.execute_input":"2022-11-20T20:39:38.159734Z","iopub.status.idle":"2022-11-20T20:39:38.169090Z","shell.execute_reply.started":"2022-11-20T20:39:38.159689Z","shell.execute_reply":"2022-11-20T20:39:38.167769Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Input tensor shape: torch.Size([1, 6])\n{'input_ids': tensor([[ 101, 2023, 2003, 1037, 3231,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}\n","output_type":"stream"}]},{"cell_type":"code","source":"inputs = {k:v.to(device) for k,v in inputs.items()}\nprint(inputs)\nwith torch.no_grad():\n    outputs = model(**inputs)\nprint(outputs)","metadata":{"execution":{"iopub.status.busy":"2022-11-20T20:39:39.079074Z","iopub.execute_input":"2022-11-20T20:39:39.079663Z","iopub.status.idle":"2022-11-20T20:39:41.207799Z","shell.execute_reply.started":"2022-11-20T20:39:39.079619Z","shell.execute_reply":"2022-11-20T20:39:41.206696Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"{'input_ids': tensor([[ 101, 2023, 2003, 1037, 3231,  102]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]], device='cuda:0')}\nBaseModelOutput(last_hidden_state=tensor([[[-0.1565, -0.1862,  0.0528,  ..., -0.1188,  0.0662,  0.5470],\n         [-0.3575, -0.6484, -0.0618,  ..., -0.3040,  0.3508,  0.5221],\n         [-0.2772, -0.4459,  0.1818,  ..., -0.0948, -0.0076,  0.9958],\n         [-0.2841, -0.3917,  0.3753,  ..., -0.2151, -0.1173,  1.0526],\n         [ 0.2661, -0.5094, -0.3180,  ..., -0.4203,  0.0144, -0.2149],\n         [ 0.9441,  0.0112, -0.4714,  ...,  0.1439, -0.7288, -0.1619]]],\n       device='cuda:0'), hidden_states=None, attentions=None)\n","output_type":"stream"}]},{"cell_type":"code","source":"outputs.last_hidden_state.size()","metadata":{"execution":{"iopub.status.busy":"2022-11-20T20:39:45.590125Z","iopub.execute_input":"2022-11-20T20:39:45.591483Z","iopub.status.idle":"2022-11-20T20:39:45.599661Z","shell.execute_reply.started":"2022-11-20T20:39:45.591433Z","shell.execute_reply":"2022-11-20T20:39:45.598473Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 6, 768])"},"metadata":{}}]},{"cell_type":"code","source":"outputs.last_hidden_state[:, 0].size()","metadata":{"execution":{"iopub.status.busy":"2022-11-20T20:39:48.615844Z","iopub.execute_input":"2022-11-20T20:39:48.616479Z","iopub.status.idle":"2022-11-20T20:39:48.623117Z","shell.execute_reply.started":"2022-11-20T20:39:48.616438Z","shell.execute_reply":"2022-11-20T20:39:48.622154Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 768])"},"metadata":{}}]},{"cell_type":"code","source":"def extract_hidden_states(batch):\n    # place model inputs on the GPU\n    inputs = {k:v.to(device) for k, v in batch.items() if k in tokenizer.model_input_names}\n    with torch.no_grad():\n        last_hidden_state = model(**inputs).last_hidden_state\n    return {\"hidden_state\": last_hidden_state[:, 0].cpu().numpy()}","metadata":{"execution":{"iopub.status.busy":"2022-11-20T20:39:50.896384Z","iopub.execute_input":"2022-11-20T20:39:50.896775Z","iopub.status.idle":"2022-11-20T20:39:50.902670Z","shell.execute_reply.started":"2022-11-20T20:39:50.896736Z","shell.execute_reply":"2022-11-20T20:39:50.901651Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"emotions_encoded.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])","metadata":{"execution":{"iopub.status.busy":"2022-11-20T20:39:51.537029Z","iopub.execute_input":"2022-11-20T20:39:51.538287Z","iopub.status.idle":"2022-11-20T20:39:51.545446Z","shell.execute_reply.started":"2022-11-20T20:39:51.538227Z","shell.execute_reply":"2022-11-20T20:39:51.544275Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"emotions_hidden = emotions_encoded.map(extract_hidden_states, batched=True)","metadata":{"execution":{"iopub.status.busy":"2022-11-20T20:39:52.391646Z","iopub.execute_input":"2022-11-20T20:39:52.392003Z","iopub.status.idle":"2022-11-20T20:40:35.766798Z","shell.execute_reply.started":"2022-11-20T20:39:52.391972Z","shell.execute_reply":"2022-11-20T20:40:35.765722Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/16 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9a60227935f4926b2735cc84cf742ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5efffc3b8be4dc8ab6afac0e24b40cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10196b6c1e6c4e1d8d8a5b2d24428070"}},"metadata":{}}]},{"cell_type":"code","source":"emotions_hidden[\"train\"][\"hidden_state\"].shape","metadata":{"execution":{"iopub.status.busy":"2022-11-20T20:44:09.155721Z","iopub.execute_input":"2022-11-20T20:44:09.156114Z","iopub.status.idle":"2022-11-20T20:44:09.313458Z","shell.execute_reply.started":"2022-11-20T20:44:09.156079Z","shell.execute_reply":"2022-11-20T20:44:09.312151Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"torch.Size([16000, 768])"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nX_train = np.array(emotions_hidden[\"train\"][\"hidden_state\"])\nX_valid = np.array(emotions_hidden[\"validation\"][\"hidden_state\"])\ny_train = np.array(emotions_hidden[\"train\"][\"label\"])\ny_valid = np.array(emotions_hidden[\"validation\"][\"label\"])\nprint(X_train.shape)\nprint(X_valid.shape)","metadata":{"execution":{"iopub.status.busy":"2022-11-20T20:43:47.589895Z","iopub.execute_input":"2022-11-20T20:43:47.590393Z","iopub.status.idle":"2022-11-20T20:43:47.769274Z","shell.execute_reply.started":"2022-11-20T20:43:47.590351Z","shell.execute_reply":"2022-11-20T20:43:47.768097Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"(16000, 768)\n(2000, 768)\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlr_clf = LogisticRegression(max_iter=3000)\nlr_clf.fit(X_train, y_train)\nlr_clf.score(X_valid, y_valid)","metadata":{"execution":{"iopub.status.busy":"2022-11-20T20:45:55.998688Z","iopub.execute_input":"2022-11-20T20:45:55.999932Z","iopub.status.idle":"2022-11-20T20:48:35.206116Z","shell.execute_reply.started":"2022-11-20T20:45:55.999884Z","shell.execute_reply":"2022-11-20T20:48:35.203576Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"0.634"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.dummy import DummyClassifier\ndummy_clf = DummyClassifier(strategy=\"most_frequent\")\ndummy_clf.fit(X_train, y_train)\ndummy_clf.score(X_valid, y_valid)","metadata":{"execution":{"iopub.status.busy":"2022-11-20T20:50:08.682748Z","iopub.execute_input":"2022-11-20T20:50:08.683151Z","iopub.status.idle":"2022-11-20T20:50:08.696013Z","shell.execute_reply.started":"2022-11-20T20:50:08.683116Z","shell.execute_reply":"2022-11-20T20:50:08.694733Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"0.352"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}